{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the dataset.zip file\n",
    "path = \"./dataset.zip\"\n",
    "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "    print(\"Extracting dataset...\")\n",
    "    zip_ref.extractall('dataset')\n",
    "\n",
    "dataset_path = \"./dataset\"\n",
    "images_path = os.path.join(dataset_path, \"images\")\n",
    "labels_path = os.path.join(dataset_path, \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split ratios\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 1 - train_ratio - val_ratio\n",
    "\n",
    "for set_type in [\"train\", \"val\", \"test\"]:\n",
    "    for content_type in [\"images\", \"labels\"]:\n",
    "        print(f\"Creating {set_type} {content_type} directory...\")\n",
    "        os.makedirs(os.path.join(dataset_path, set_type, content_type), exist_ok=True)\n",
    "        \n",
    "all_files = [file for file in os.listdir(images_path) if  os.path.isfile(os.path.join(images_path, file))]\n",
    "random.shuffle(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the split indices\n",
    "total_files = len(all_files)\n",
    "train_end = int(train_ratio * total_files)\n",
    "val_end = int((train_ratio + val_ratio) * total_files)\n",
    "\n",
    "# Split files\n",
    "train_files = all_files[:train_end]\n",
    "val_files = all_files[train_end:val_end]\n",
    "test_files = all_files[val_end:]\n",
    "\n",
    "def copy_files(files, set_type):\n",
    "    print(f\"Copying {set_type} files...\")\n",
    "    for file in files:\n",
    "        shutil.copy(os.path.join(images_path, file), os.path.join(dataset_path, set_type, \"images\"))\n",
    "        label_file = file.rsplit(\".\", 1)[0] + \".txt\"\n",
    "        shutil.copy(os.path.join(labels_path, label_file), os.path.join(dataset_path, set_type, \"labels\"))\n",
    "        \n",
    "copy_files(train_files, \"train\")\n",
    "copy_files(val_files, \"val\")\n",
    "copy_files(test_files, \"test\")\n",
    "\n",
    "print(\"Dataset split complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes\n",
    "with open(\"dataset/classes.txt\", \"r\") as file:\n",
    "    class_names = [name.strip() for name in file.readlines()]\n",
    "    \n",
    "print(class_names)\n",
    "\n",
    "# Creating a data.yaml file with absolute paths\n",
    "current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "with open(\"dataset/data.yaml\", \"w\") as file:\n",
    "    file.write(f\"train: {os.path.join(current_dir, 'dataset/train')}\\n\")\n",
    "    file.write(f\"val: {os.path.join(current_dir, 'dataset/val')}\\n\")\n",
    "    file.write(f\"test: {os.path.join(current_dir, 'dataset/test')}\\n\")\n",
    "    file.write(\"nc: \" + str(len(class_names)) + \"\\n\")\n",
    "    file.write(\"names: \" + str(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8x\")\n",
    "\n",
    "# model.predict(\"./input_images/image.png\", save=True)\n",
    "\n",
    "results = model.train(data=\"dataset/data.yaml\", epochs=5, imgsz=640)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
